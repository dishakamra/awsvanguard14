{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building conversational applications with the Converse API\n",
    "\n",
    "In this notebook, you learn how to use the flexible Converse API to integrate external capabilities into conversational applications.\n",
    "\n",
    "Certain conversational applications demand an adaptable sequence of calls to language models and various utilities depending on user input. The Converse API enables building such flexible dialogue agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "In this task, you set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create a service client by name using the default session.\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "bedrock_client = boto3.client(\n",
    "    'bedrock-runtime',\n",
    "    region_name = os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")\n",
    "model_id = \"amazon.nova-lite-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synergizing Reasoning and Acting in Language Models Framework\n",
    "\n",
    "In this task, the Converse API enables integrating large language models with external capabilities to obtain additional information that results in more accurate and factual responses in a conversation.\n",
    "\n",
    "The Converse framework allows conversational models like Nova to generate natural language responses in an ongoing dialogue. Within these responses, you can configure markup like [tools] tags to trigger calls to external capabilities.\n",
    "\n",
    "Large language models can generate both explanations for their reasoning and task-specific responses in an alternating fashion.\n",
    "\n",
    "Producing reasoning explanations enables the models to infer, monitor, and revise action plans, and even handle unexpected scenarios. The action step allows the models to interface with and obtain information from external sources such as knowledge bases or environments.\n",
    "\n",
    "Next, you will build a simple calculator agent to add, subtract, multiply, and divide using the Converse API. The purpose is to demonstrate how to register the calculator functions as conversational capabilities that can be called through the Converse API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write a function to add, subtract, multiply, and divide two numbers\n",
    "\n",
    "def calculator(oper1, oper2, operator):\n",
    "\n",
    "    def add(a, b):\n",
    "        return a+b\n",
    "\n",
    "    def subtract(a, b):\n",
    "        return a-b\n",
    "\n",
    "    def multiply(a, b):\n",
    "        return a*b\n",
    "\n",
    "    def divide(a, b):\n",
    "        if b==0:\t\t\n",
    "            return \"Cannot divide by zero\"\n",
    "        else:\n",
    "            return float(a/b)\n",
    "        \n",
    "    if operator == '+' or operator == 'add':\n",
    "        return add(oper1, oper2)\n",
    "    elif operator == '-' or operator == 'subtract':\n",
    "        return subtract(oper1,oper2)\n",
    "    elif operator == '*' or operator == 'multiply':\n",
    "        return multiply(float(oper1), float(oper2))\n",
    "    elif operator == '/' or operator == 'divide':\n",
    "        return divide(oper1,oper2)\n",
    "    else:\n",
    "        return \"Invalid operator\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you extend the conversational assistant with access a search engine like DuckDuckGo.\n",
    "\n",
    "The intent of the following code is to demonstrate:\n",
    "\n",
    "- Register it as an additional capability with our Converse API\n",
    "- Update the prompt templates to invoke this capability based on certain trigger phrases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def duckduckgo_search(query: str):\n",
    "    tool = DuckDuckGoSearchRun()\n",
    "    result = tool.invoke(query)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you define a tool configuration to register external capabilities that can be invoked within conversations with an Amazon Bedrock model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tool_config = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"duckduckgo_search\",\n",
    "                \"description\": \"Useful when you need to search the internet and find current information.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Your search query.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\n",
    "                            \"query\"\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"calculator\",\n",
    "                \"description\": \"Useful when you need to answer questions that involve adding, subtracting, multiplying, and dividing two numbers. The division can go up to 15 decimal points.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"oper1\": {\n",
    "                                \"type\": \"integer\",\n",
    "                                \"description\": \"first operand.\"\n",
    "                            },\n",
    "                            \"oper2\": {\n",
    "                                \"type\": \"integer\",\n",
    "                                \"description\": \"second operand.\"\n",
    "                            },\n",
    "                            \"operator\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"operator.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\n",
    "                            \"oper1\",\"oper2\",\"operator\"\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you create a function to call the converse API to converse with an Amazon Bedrock model to generate text responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(bedrock_client, model_id, tool_config, message_list):\n",
    "    \n",
    "    response = bedrock_client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=message_list,\n",
    "        toolConfig=tool_config,\n",
    "        system=[{\"text\": \"You are a helpful assistant. You can use tools to help you answer questions. You should always use tools to help you with calculations. You can also use tools to help you search the internet and find current information.\"}]\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, you create a function to run the tools that the text generated by the Converse API described implementing the ACT of ReACT. This function is the core logic for the interpretation of the text generation response:\n",
    "* It loops across all content blocks of the response\n",
    "* It calls the functions of the tools defined above based on what the model told it to do.\n",
    "* It appropriately adds the output of the function calls of the tools defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_the_tools(response_message):\n",
    "    \n",
    "    response_content_blocks = response_message['content']\n",
    "    \n",
    "    follow_up_content_blocks = []\n",
    "    \n",
    "    for content_block in response_content_blocks:\n",
    "        if 'toolUse' in content_block:\n",
    "            tool = content_block['toolUse']\n",
    "            \n",
    "            if tool['name'] == 'duckduckgo_search':\n",
    "                output_search = duckduckgo_search(tool['input']['query'])\n",
    "                follow_up_content_blocks.append({\n",
    "                    \"toolResult\": {\n",
    "                        \"toolUseId\": tool['toolUseId'],\n",
    "                        \"content\": [{\"json\": {\"result\": output_search}}]\n",
    "                    }\n",
    "                })\n",
    "            elif tool['name'] == 'calculator':\n",
    "                output_calculator = calculator(tool['input']['oper1'], tool['input']['oper2'], tool['input']['operator'])\n",
    "                follow_up_content_blocks.append({\n",
    "                    \"toolResult\": {\n",
    "                        \"toolUseId\": tool['toolUseId'],\n",
    "                        \"content\": [{\"json\": {\"result\": output_calculator}}]\n",
    "                    }\n",
    "                })\n",
    "     \n",
    "    if len(follow_up_content_blocks) > 0:\n",
    "        follow_up_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": follow_up_content_blocks,\n",
    "        }\n",
    "        \n",
    "        return follow_up_message\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `converse` function run an infinite loop and implements the following logic:\n",
    "1. Calls the `generate_text` function for the Converse API of Bedrock.\n",
    "2. Appends the output of the model in the message list as the Converse API will need the context.\n",
    "2. Calls the `run_the_tools` function to run the tools based on the response of #1.\n",
    "3. Appends the output of the `run_the_tools` to the message list as the Converse API will need the answer in the context.\n",
    "4. Decides if it needs to go back to #1 if there was a tool used or end the loop\n",
    "\n",
    "It finally sends back the list of messages containing the whole conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def converse(prompt, bedrock_client, model_id, tool_config):\n",
    "    \n",
    "    message_list = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [ { \"text\": prompt } ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    while True:\n",
    "        response = generate_text(bedrock_client, model_id, tool_config, message_list)\n",
    "        \n",
    "        response_message = response['output']['message']\n",
    "        message_list.append(response_message)\n",
    "        \n",
    "        follow_up_message = run_the_tools(response_message)\n",
    "        \n",
    "        if follow_up_message is None:\n",
    "            # No remaining work to do, return final response to user\n",
    "            break\n",
    "        else:\n",
    "            message_list.append(follow_up_message)\n",
    "            \n",
    "    return message_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you send your query to the `converse` function that orchestrates the end-to-end flow to have a conversation with the Amazon Bedrock model leveraging the integrated tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MESSAGES:\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": [\n",
      "            {\n",
      "                \"text\": \"What is Amazon SageMaker? What is launch year multiplied by 2\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": [\n",
      "            {\n",
      "                \"text\": \"<thinking> I need to first define what Amazon SageMaker is and then calculate the launch year multiplied by 2. I will use a search tool to find the launch year of Amazon SageMaker and then a calculator tool to perform the multiplication. </thinking>\\n\"\n",
      "            },\n",
      "            {\n",
      "                \"toolUse\": {\n",
      "                    \"toolUseId\": \"tooluse_YozOF4wRT3KM6G5_mJD4Ww\",\n",
      "                    \"name\": \"duckduckgo_search\",\n",
      "                    \"input\": {\n",
      "                        \"query\": \"What is Amazon SageMaker?\"\n",
      "                    }\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"toolUse\": {\n",
      "                    \"toolUseId\": \"tooluse_TwFg0E4GRV2_bw21-6IKrg\",\n",
      "                    \"name\": \"duckduckgo_search\",\n",
      "                    \"input\": {\n",
      "                        \"query\": \"Amazon SageMaker launch year\"\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": [\n",
      "            {\n",
      "                \"toolResult\": {\n",
      "                    \"toolUseId\": \"tooluse_YozOF4wRT3KM6G5_mJD4Ww\",\n",
      "                    \"content\": [\n",
      "                        {\n",
      "                            \"json\": {\n",
      "                                \"result\": \"Note The original Amazon SageMaker has been renamed SageMaker AI. It is available in the next generation Amazon SageMaker for those who wish to use it alongside additional capabilities, or as a standalone service for those who wish to focus specifically on building, training, and deploying AI and ML models at scale. Aug 6, 2025 \\u00b7 What is Amazon SageMaker ? Amazon SageMaker is a fully managed service offered by Amazon Web Services (AWS) that simplifies the process of building, training, and deploying machine learning (ML) models. It equips users with the necessary tools to create predictive analytics applications and automates much of the heavy lifting required to develop a production-ready artificial intelligence (AI ... Oct 30, 2024 \\u2014 Amazon SageMaker is a fully managed service that simplifies building, training, and deploying machine learning models, automating tasks and reducing complexity. Amazon SageMaker AI is a fully managed machine learning (ML) service. With SageMaker AI, data scientists and developers can quickly and confidently build, train, and deploy ML models into a production-ready hosted environment. Dec 3, 2024 \\u2014 The all-new SageMaker includes virtually all of the components you need for data exploration, preparation and integration, big data processing, fast SQL ...\"\n",
      "                            }\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            },\n",
      "            {\n",
      "                \"toolResult\": {\n",
      "                    \"toolUseId\": \"tooluse_TwFg0E4GRV2_bw21-6IKrg\",\n",
      "                    \"content\": [\n",
      "                        {\n",
      "                            \"json\": {\n",
      "                                \"result\": \"Aug 11, 2025 \\u2014 Amazon SageMaker AI launched at re:Invent 2017. November 28, 2017 ... Nov 26, 2024 \\u2014 AWS addressed this gap by launching SageMaker in 2017, offering a fully managed environment for developing, training, and deploying machine learning models. It ... When AWS launched Amazon SageMaker AI in 2017, we wanted to bring customers a way to accelerate their AI workflows in a low-cost environment. Aug 18, 2025 \\u2014 Launched at AWS re:Invent 2024 , the next generation of Amazon SageMaker is expediting innovation for organizations such as ATPCO through a unified data ... When we launched Amazon SageMaker AI in 2017, we had a clear mission: put machine learning in the hands of any developer, regardless of skill level.\"\n",
      "                            }\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": [\n",
      "            {\n",
      "                \"text\": \"<thinking> I have found the definition of Amazon SageMaker and its launch year. Now, I will use the calculator tool to multiply the launch year by 2. </thinking> \"\n",
      "            },\n",
      "            {\n",
      "                \"toolUse\": {\n",
      "                    \"toolUseId\": \"tooluse_gHDDXut4SQWupdvcTYMo4A\",\n",
      "                    \"name\": \"calculator\",\n",
      "                    \"input\": {\n",
      "                        \"oper1\": 2017,\n",
      "                        \"oper2\": 2,\n",
      "                        \"operator\": \"*\"\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": [\n",
      "            {\n",
      "                \"toolResult\": {\n",
      "                    \"toolUseId\": \"tooluse_gHDDXut4SQWupdvcTYMo4A\",\n",
      "                    \"content\": [\n",
      "                        {\n",
      "                            \"json\": {\n",
      "                                \"result\": 4034.0\n",
      "                            }\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": [\n",
      "            {\n",
      "                \"text\": \"<thinking> I have successfully calculated the launch year of Amazon SageMaker multiplied by 2. I can now provide the complete answer to the user. </thinking>\\n\\nAmazon SageMaker is a fully managed service offered by Amazon Web Services (AWS) that simplifies the process of building, training, and deploying machine learning models. It equips users with the necessary tools to create predictive analytics applications and automates much of the heavy lifting required to develop a production-ready artificial intelligence (AI) or machine learning (ML) model.\\n\\nThe launch year of Amazon SageMaker is 2017. When multiplied by 2, the result is 4034.\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# query = \"What is an Astronomical unit (AU)? Express the circumference of the earth in AU\"\n",
    "query = \"What is Amazon SageMaker? What is launch year multiplied by 2\"\n",
    "\n",
    "messages = converse(query, bedrock_client, model_id, tool_config)\n",
    "\n",
    "print(\"\\nMESSAGES:\\n\")\n",
    "print(json.dumps(messages, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully integrated Amazon Bedrock with custom capabilities by utilizing Converse API and tool framework."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:250115765102:studio-lifecycle-config/lcc-kernel"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
