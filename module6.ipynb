{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da609b5",
   "metadata": {},
   "source": [
    "# Module 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f5f11",
   "metadata": {},
   "source": [
    "## Basic LangChain invoke and chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abaade34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Bonjour! Comment ça va? \\n\\n(Translation: Hi! How are you?)' additional_kwargs={} response_metadata={'ResponseMetadata': {'RequestId': '99852a5a-4ed9-4f2d-8708-3ee019191790', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 28 Sep 2025 09:40:51 GMT', 'content-type': 'application/json', 'content-length': '261', 'connection': 'keep-alive', 'x-amzn-requestid': '99852a5a-4ed9-4f2d-8708-3ee019191790'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [505]}, 'model_name': 'us.amazon.nova-lite-v1:0'} id='run--40dfaabd-35f5-47e8-8664-362f34342657-0' usage_metadata={'input_tokens': 9, 'output_tokens': 17, 'total_tokens': 26, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Uses ChatBedrockConverse hidden under init_chat_model\n",
    "model = init_chat_model(\n",
    "    model=\"us.amazon.nova-lite-v1:0\", \n",
    "    model_provider=\"bedrock_converse\"\n",
    ")\n",
    "\n",
    "messages= [\n",
    "    SystemMessage(\"Translate the following from English into French\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "response= model.invoke(messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a85b41",
   "metadata": {},
   "source": [
    "### Chaining the model with the StrOutputParser to render the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3abfc335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour! \n",
      "\n",
      "If you have any specific sentences or phrases you'd like translated from English to French, feel free to share them!\n"
     ]
    }
   ],
   "source": [
    "chain = model | StrOutputParser()\n",
    "\n",
    "print(chain.invoke(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da3a75b",
   "metadata": {},
   "source": [
    "## LangChain PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e669c1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao! \n",
      "\n",
      "Se hai bisogno di aiuto con la traduzione di un testo più lungo o di una frase specifica, sono qui per aiutarti.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Set the system prompt template using language as a variable\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "# Set the final prompt combining system prompt and the user's text\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template), \n",
    "    (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "# Chain the prompt_template, model and renderer\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "# Invoke the chain passing in the arguments for the prompt template\n",
    "response = chain.invoke({\n",
    "    \"language\": \"Italian\", \n",
    "    \"text\": \"hi!\"\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d8c06",
   "metadata": {},
   "source": [
    "## LangChain conversation history in DynamoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a58fb7",
   "metadata": {},
   "source": [
    "### Setting up the DynamoDB table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06134c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "table_name = \"langchain-conversation-history\"\n",
    "\n",
    "dynamodb = boto3.client('dynamodb')\n",
    "response = dynamodb.create_table(\n",
    "    TableName=table_name,\n",
    "    BillingMode='PAY_PER_REQUEST',\n",
    "    AttributeDefinitions=[\n",
    "        {\n",
    "            'AttributeName': 'SessionId',\n",
    "            'AttributeType': 'S'\n",
    "        }\n",
    "    ],\n",
    "    KeySchema=[\n",
    "        {\n",
    "            'AttributeName': 'userId',\n",
    "            'KeyType': 'HASH'\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Wait for table to be active\n",
    "waiter = dynamodb.get_waiter('table_exists')\n",
    "waiter.wait(TableName=table_name)\n",
    "\n",
    "ttl_response = dynamodb.update_time_to_live(\n",
    "    TableName=table_name,\n",
    "    TimeToLiveSpecification={\n",
    "        'AttributeName': 'expireAt',\n",
    "        'Enabled': True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd6ba2",
   "metadata": {},
   "source": [
    "### Testing with DynamoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import DynamoDBChatMessageHistory\n",
    "\n",
    "history = DynamoDBChatMessageHistory(\n",
    "    table_name=\"langchain-conversation-history\", \n",
    "    session_id=\"1\"\n",
    ")\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "history.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2dc441",
   "metadata": {},
   "source": [
    "### Setting up the model, prompt template and chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# Typical model definition\n",
    "model = init_chat_model(\n",
    "    model=\"us.amazon.nova-lite-v1:0\", \n",
    "    model_provider=\"bedrock_converse\"\n",
    ")\n",
    "\n",
    "# Creates a prompt template that will have the system prompt, the\n",
    "# history from the variable history and human question\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Creates a chain by starting with the prompt_template, the model\n",
    "# and parsing the output\n",
    "chain = prompt_template | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b3bd6d",
   "metadata": {},
   "source": [
    "### Adding the message history in the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf02492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    # Existing LangChain processing pipeline\n",
    "    chain, \n",
    "    \n",
    "    # Factory function that sends session_id as a parameter to the \n",
    "    # DynamoDBChatMessageHistory() function which creates a new history \n",
    "    # per session\n",
    "    lambda session_id: DynamoDBChatMessageHistory(    \n",
    "        table_name=\"langchain-conversation-history\", \n",
    "        session_id=session_id, # From the parameter\n",
    "        ttl=120\n",
    "    ),\n",
    "    \n",
    "    # Tells the wrapper that user input comes from the question field\n",
    "    input_messages_key=\"question\", \n",
    "    \n",
    "    # Maps to the MessagesPlaceholder variable name in the prompt template\n",
    "    history_messages_key=\"history\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139ef42d",
   "metadata": {},
   "source": [
    "### Setting the session_id and invoking the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39ac45bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Alice. If you have any other questions or need assistance with something else, feel free to ask!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the session_id in the config so it can be passed\n",
    "config = { \"configurable\": { \"session_id\": \"24\" } }\n",
    "\n",
    "# Invoking the chain twice\n",
    "chain_with_history.invoke({\"question\": \"Hi! I'm Alice.\"}, config=config)\n",
    "chain_with_history.invoke({\"question\": \"What's my name?\"}, config=config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
